---
layout: default
permalink: /keynote-speakers/
title: Keynote speakers
description: Keynote speakers
nav: true

---

<h1><b>Keynote speakers</b></h1>

---
<div style="display: flex; align-items: center;">
  <!-- Image on the left -->
  <img src="/assets/img/William-Agnew.jpg" alt="Description" style="width: 150px; margin-right: 20px;">

  <!-- Text on the right -->
  <div>
    <b>Speaker:</b> Dr. William Agnew<br>
    <b>Pronouns:</b> He/They <br>
    <b>Bio:</b> Dr. William Agnew is a CBI postdoc fellow at CMU. William received his Ph.D. from University of Washington with Sidd Srinivasa, where he worked on AI ethics, critical AI, and robotics. William also helped found Queer in AI. William is interested in developing and sharing tools and ideas that go beyond participatory design and allow marginalized individuals and communities to own and meaningfully control their data and models derived from that data. Building on ideas from usable security/privacy, usage licenses, and indigenous data sovereignty, William wants to contribute to data and AI futures where individuals and communities know where their data is and can remove, add, or change their data in different datasets.
  </div>
</div>
<h5><b>Title:</b> Mobilizing the Queer Community in AI Policy</h5>
<b>Abstract:</b> Effective regulation of AI is vital for ensuring AI advances our goals of equity, diversity, inclusion, and justice. Legislative and regulatory bodies across the world are currently deciding how to regulate AI, and how to operationalize those regulations. However, marginalized communities often lack political power and networks to ensure their perspectives are heard when creating regulations. In this talk, I provide some background on current efforts to regulate AI and how they consider (or fail to consider) EDI. I then discuss Queer in AI's policy engagement strategy, showing how we have educated and mobilized our community to grow our impact and highlighting specific challenges marginalized communities face when doing policy work. Finally, I discuss Queer in AI's specific policy engagements and positions, and how they may lead to more just AI.

---

<div style="display: flex; align-items: center;">
  <!-- Image on the left -->
  <img src="/assets/img/Karina-Gibert.jpg" alt="Description" style="width: 150px; margin-right: 20px;">

  <!-- Text on the right -->
  <div>
    <b>Speaker:</b> Prof. Karina Gibert<br>
    <b>Bio:</b> Prof. William Agnew is Full professor and Head Director of Intelligent Data Science and Artificial Intelligence Research Center (IDEAI-UPC) Dean of the Official Professional College of Informatics Engineering of Catalonia Data Mining, Data Science, KEMLg, eHealth, environmental applications, Hackingbullipedia, Intelligent Decision Support Systems, Preprocessing, Postprocessing, Knowledge Discovery from Data bases, Artificial Intelligence, ethics in AI, explainable AI.
  </div>
</div>
<h5><b>Title:</b> TBD</h5>
<b>Abstract:</b> TBD

---

<div style="display: flex; align-items: center;">
  <!-- Image on the left -->
  <img src="/assets/img/mlq_image.jpg" alt="Description" style="width: 150px; margin-right: 20px;">

  <!-- Text on the right -->
  <div>
    <b>Speaker:</b> Dr. Moreno La Quatra<br>
    <b>Bio:</b> Moreno La Quatra is a Research Fellow at the Speech Technologies and Machine Learning Lab at Kore University of Enna (Italy). Moreno's research focuses on deep learning, audio processing, and natural language processing, with a particular emphasis on inclusive communication. He has significantly contributed to the E-MIMIC project, which aims at detecting and correcting non-inclusive language usage in text across multiple languages. His work emphasizes the importance of language as a tool for inclusivity and social change. Moreno is committed to developing NLP and AI methodologies that promote respectful and inclusive communication, ensuring that language use reflects and respects diversity in all its forms.
  </div>
</div>
<h5><b>Title:</b> Promoting Inclusivity through Natural Language Processing</h5>
<b>Abstract:</b> Language has the power to promote inclusivity and respect, but it can also reinforce bias and discrimination, reflecting the inequalities of our world. Building a fairer society requires addressing these issues head-on. While modern AI models often exhibit intrinsic biases, researchers worldwide are working to resolve these problems. This talk takes a different perspective by exploring how deep learning and natural language processing (NLP) approaches can be used as a tool to identify non-inclusive language and suggest more inclusive alternatives. The talk will also introduce the Inclusively tool, which provides interfaces to AI models that can be used to proofread text for inclusivity. Designed for both general users and experts, it encourages feedback and continuous improvement through a human-in-the-loop approach.